{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pima Indians Diabetes Dataset: \n",
    "## `Diabetes.csv`\n",
    "---\n",
    "## Context\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
    "\n",
    "## Content\n",
    "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "|Variable | Description |\n",
    "|---|---|\n",
    "|`Pregnancies` | Number of times pregnant |\n",
    "|`Glucose`| Plasma glucose concentration a 2 hours in an oral glucose tolerance test |\n",
    "|`BloodPressure` | Diastolic blood pressure (mm Hg) |\n",
    "|`SkinThickness` | Triceps skin fold thickness (mm) |\n",
    "|`Insulin` | 2-Hour serum insulin (mu U/ml) |\n",
    "|`BMI` | Body mass index (weight in kg/(height in m)^2) |\n",
    "|`DiabetesPedigreeFunction` | Diabetes pedigree function |\n",
    "|`Age` | Age (years) |\n",
    "|`Outcome` | Class variable (0 or 1) |\n",
    "\n",
    "---\n",
    "\n",
    "*Sources:*\n",
    "* *Original owners: National Institute of Diabetes and Digestive and Kidney Diseases*\n",
    "* *Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu) Research Center, RMI Group Leader,  Applied Physics Laboratory, The Johns Hopkins University*\n",
    "\n",
    "*Original Date Received: 9 May 1990* \n",
    "\n",
    "*Retrieved from Kaggle 22 AUG 2021*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas_profiling\n",
    "\n",
    "diabetes = pd.read_csv('data/diabetes.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "if len(glob('profiling/diabetes.html')) == 0:\n",
    "    diabetes.profile_report().to_file('profiling/diabetes.html')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Issues Observed:\n",
    "* No missing values or duplicate rows. **Awesome!**\n",
    "* 8 numeric variables and 1 categorical.\n",
    "* Some zeroes in `BloodPressure`, `BMI` - not compatible with life. Impute values.\n",
    "* A lot of zeroes in `SkinThickness` - assumed not measured. Impute values.\n",
    "* A lot of zeroes in `Insulin` - assumed not taking insulin. Leave for now.\n",
    "* Potential correlation between `Age` and `Glucose`. This may be due to zeros, but inclined to leave alone.\n",
    "* As above for `Insulin` and `SkinThickness`.\n",
    "\n",
    "\n",
    "This step replaces the zeroes with imputed values. Tried means first, but medians is better for skew distro."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "diabetes['BloodPressure'] = diabetes['BloodPressure'].replace(0, diabetes[diabetes['BloodPressure'] > 0].BloodPressure.median())\n",
    "diabetes['BMI'] = diabetes['BMI'].replace(0, diabetes[diabetes['BMI'] > 0].BloodPressure.mean())\n",
    "diabetes['SkinThickness'] = diabetes['SkinThickness'].replace(0, diabetes[diabetes['SkinThickness'] > 0].BloodPressure.median())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quick check imputation has worked.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "if len(glob('profiling/diabetes_post_impute.html')) == 0:\n",
    "    diabetes.profile_report().to_file('profiling/diabetes_post_impute.html')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "All good."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test Splitting \n",
    "Let's stratify by diabetes outcome so that there's equal proportions for train and test."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.drop(['Outcome'], axis = 1), \n",
    "                                                    diabetes['Outcome'], \n",
    "                                                    test_size = 0.4, \n",
    "                                                    random_state = 42, \n",
    "                                                    stratify = diabetes['Outcome'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Fitting the Logistic Regression Model\n",
    "\n",
    "This is a supervised binary classification problem. Logistic regression is a pretty good first model to try (and familiar to a statistician).\n",
    "\n",
    "*Why LogisticRegressionCV*\n",
    "\n",
    "Here 100 iterations isn't enough, so let's set `max_iter = 1000`. The other parameters `n_jobs = -1` uses all the CPU cores available to train (but there's only two on this VM and it doesn't take long to train anyway)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "LogReg = LogisticRegressionCV(cv = 10, max_iter = 1000, n_jobs = -1)\n",
    "LogReg.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=10, max_iter=1000, n_jobs=-1)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "LogReg.score(X_train, y_train) # Mean Accuracy = (TP + TN) / (P + N)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7804347826086957"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "LogReg.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.737012987012987"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both train and test \\>70% accurate out of the box. That's not bad."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding StandardScaler\n",
    "Scales via: $ Z = \\frac {(x_i - \\mu)} {\\sigma}$ this should stop factors with larger scales or variance unduly influencing fitting.\n",
    "\n",
    "A small improvement."
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pl_s = Pipeline([(\"Scaler\", StandardScaler()), \n",
    "               (\"LogReg\", LogisticRegressionCV(cv = 10, max_iter = 5000, n_jobs = -1))\n",
    "              ])\n",
    "              \n",
    "\n",
    "pl_s.fit(X_train, y_train)\n",
    "\n",
    "display(\"Train: \" + str(pl_s.score(X_train, y_train))[0:4])\n",
    "display(\"Test: \" + str(pl_s.score(X_test, y_test))[0:4])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Train: 0.78'"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Test: 0.75'"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adding Interactions\n",
    "\n",
    "Overfitting in practice. Up to $3^{rd}$ order interactions ..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pl_s_3 = Pipeline([(\"Scaler\", StandardScaler()), \n",
    "                 (\"Poly\", PolynomialFeatures(degree = 3, interaction_only = True)), \n",
    "                 (\"LogReg\", LogisticRegressionCV(cv = 10, max_iter = 5000, n_jobs = -1))\n",
    "              ])\n",
    "              \n",
    "\n",
    "pl_s_3.fit(X_train, y_train)\n",
    "\n",
    "display(\"Train: \" + str(pl_s_3.score(X_train, y_train))[0:4])\n",
    "display(\"Test: \" + str(pl_s_3.score(X_test, y_test))[0:4])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Train: 0.85'"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Test: 0.69'"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop to $2^{nd}$ order interactions ..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pl_s_2 = Pipeline([(\"Scaler\", StandardScaler()), \n",
    "                 (\"Poly\", PolynomialFeatures(degree = 2, interaction_only = True)), \n",
    "                 (\"LogReg\", LogisticRegressionCV(cv = 10, max_iter = 5000, n_jobs = -1))\n",
    "              ])\n",
    "              \n",
    "\n",
    "pl_s_2.fit(X_train, y_train)\n",
    "\n",
    "display(\"Train: \" + str(pl_s_2.score(X_train, y_train))[0:4])\n",
    "display(\"Test: \" + str(pl_s_2.score(X_test, y_test))[0:4])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Train: 0.80'"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Test: 0.72'"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try *l1* regularisation..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pl_s_2_l1 = Pipeline([(\"Scaler\", StandardScaler()), \n",
    "                 (\"Poly\", PolynomialFeatures(degree = 2, interaction_only = True)), \n",
    "                 (\"LogReg\", LogisticRegressionCV(cv = 10, \n",
    "                                                 max_iter = \n",
    "                                                 5000, n_jobs = -1, \n",
    "                                                 penalty = 'l1', \n",
    "                                                 solver = 'saga'))\n",
    "              ])\n",
    "              \n",
    "\n",
    "pl_s_2_l1.fit(X_train, y_train)\n",
    "\n",
    "display(\"Train: \" + str(pl_s_2_l1.score(X_train, y_train))[0:4])\n",
    "display(\"Test: \" + str(pl_s_2_l1.score(X_test, y_test))[0:4])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Train: 0.77'"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Test: 0.74'"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Support Vector Classification"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pl_svc = Pipeline([(\"Scaler\", StandardScaler()),\n",
    "                 (\"SVC\", SVC())\n",
    "              ])\n",
    "              \n",
    "\n",
    "pl_svc.fit(X_train, y_train)\n",
    "\n",
    "display(\"Train: \" + str(pl_svc.score(X_train, y_train))[0:4])\n",
    "display(\"Test: \" + str(pl_svc.score(X_test, y_test))[0:4])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Train: 0.84'"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Test: 0.73'"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing not great out of the box ... maybe some value in tuning regularization strength and try a few kernels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_params = {'SVC__C': np.linspace(0.1,2,20), \n",
    "                 'SVC__kernel': ['linear','poly', 'rbf']}\n",
    "\n",
    "search = GridSearchCV(pl_svc, search_params)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "display(search.best_params_)\n",
    "display(\"Train: \" + str(search.best_score_)[0:4])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'SVC__C': 0.7, 'SVC__kernel': 'rbf'}"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Train: 0.79'"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# Test train at C = 0.7\n",
    "\n",
    "pl_svc = Pipeline([(\"Scaler\", StandardScaler()),\n",
    "                 (\"SVC\", SVC(C=0.7))\n",
    "              ])\n",
    "              \n",
    "\n",
    "pl_svc.fit(X_train, y_train)\n",
    "display(\"Test: \" + str(pl_svc.score(X_test, y_test))[0:4])\n",
    "\n",
    "# Not much better than log-reg."
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "'Test: 0.74'"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a feel for using sci-kit learn using the data, let's build a framework to train, tune and evaluate a few sensible models and compare. Over to the `pima_diabetes_framework.ipynb` for more ..."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}