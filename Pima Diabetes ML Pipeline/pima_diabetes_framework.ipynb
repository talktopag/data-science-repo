{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pima Indians Diabetes ML Framework\n",
    "\n",
    "Fitting multiple models and evaluating performance. See `pima_diabetes_dev.ipynb` for info."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "General Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scikit-learn Specific Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import `diabetes.csv` and impute values into relevant columns. See `pima_diabetes_dev.ipynb` for info."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "diabetes['BloodPressure'] = diabetes['BloodPressure'].replace(0, diabetes[diabetes['BloodPressure'] > 0].BloodPressure.median())\n",
    "diabetes['BMI'] = diabetes['BMI'].replace(0, diabetes[diabetes['BMI'] > 0].BloodPressure.mean())\n",
    "diabetes['SkinThickness'] = diabetes['SkinThickness'].replace(0, diabetes[diabetes['SkinThickness'] > 0].BloodPressure.median())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train-Test Splitting \n",
    "\n",
    "Let's stratify by diabetes outcome so that there's equal proportions for train and test."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.drop(['Outcome'], axis = 1), diabetes['Outcome'], test_size = 0.4, random_state = 42,stratify = diabetes['Outcome'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitting framework: \n",
    "\n",
    "* Fits either Logistic Regression or Support Vector, Random Forest or Gradient Boosting Classifiers\n",
    "* Tunes hyper-parameters with `GridSearchCV`\n",
    "* Evaluates Training and Test Accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "models = {\"logreg\": LogisticRegression(), \"svc\": SVC(), \"rf\": RandomForestClassifier(), \"gb\": GradientBoostingClassifier()}\n",
    "\n",
    "models_desc = {\n",
    "    \"logreg\": \"Logistic Regression\", \n",
    "    \"svc\": \"Support Vector Classifier\", \n",
    "    \"rf\": \"Random Forest Classifier\",\n",
    "    \"gb\": \"Gradient Boosting Classifier\"\n",
    "}\n",
    "\n",
    "models_out = []\n",
    "\n",
    "tuning_params_gb = dict(gb__min_samples_leaf = [3, 4, 5], gb__min_samples_split = [0.005, 0.01, 0.02, 0.05], gb__max_depth = [3, 4, 5])\n",
    "tuning_params_logreg = dict(logreg__penalty = ['l2', 'none'])\n",
    "tuning_params_svc = dict(svc__C = np.linspace(0.1,2,20), svc__kernel = ['linear','poly', 'rbf'])\n",
    "tuning_params_rf = dict(rf__max_depth = [1, 3, 5, 10, 15, 20], rf__max_features = ['auto', 'sqrt'], rf__min_samples_leaf = [2, 3, 4], rf__min_samples_split = [0.005, 0.01, 0.02, 0.05])\n",
    "\n",
    "tuning_params = dict(logreg=tuning_params_logreg, svc = tuning_params_svc, rf = tuning_params_rf, gb = tuning_params_gb)\n",
    "\n",
    "for model in models:\n",
    "    pl = Pipeline([(\"Scale\", StandardScaler()), (model, models[model])])\n",
    "    searcher = GridSearchCV(pl, tuning_params[model])\n",
    "    searcher.fit(X_train, y_train)\n",
    "\n",
    "    search_df = pd.DataFrame(searcher.cv_results_)\n",
    "    mean_test = float(search_df[search_df['params'] == searcher.best_params_]['mean_test_score'].drop_duplicates())\n",
    "    mean_sd = float(search_df[search_df['params'] == searcher.best_params_]['std_test_score'].drop_duplicates())\n",
    "    \n",
    "    models_out.append([models_desc[model],\n",
    "        mean_test,\n",
    "        mean_sd,\n",
    "        searcher.score(X_test, y_test), \n",
    "        searcher.best_params_])\n",
    "\n",
    "summary_stats = pd.DataFrame.from_records(models_out, columns= ['Model', 'Mean_Train_Acc', 'Std_Train_Acc', 'Test_Acc', 'Best_Params'])\n",
    "\n",
    "display(summary_stats)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "                          Model  Mean_Train_Acc  Std_Train_Acc  Test_Acc  \\\n",
       "0           Logistic Regression        0.760870       0.032969  0.737013   \n",
       "1     Support Vector Classifier        0.793478       0.050047  0.740260   \n",
       "2      Random Forest Classifier        0.793478       0.035721  0.733766   \n",
       "3  Gradient Boosting Classifier        0.795652       0.046828  0.750000   \n",
       "\n",
       "                                         Best_Params  \n",
       "0                          {'logreg__penalty': 'l2'}  \n",
       "1              {'svc__C': 0.7, 'svc__kernel': 'rbf'}  \n",
       "2  {'rf__max_depth': 15, 'rf__max_features': 'aut...  \n",
       "3  {'gb__max_depth': 5, 'gb__min_samples_leaf': 3...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean_Train_Acc</th>\n",
       "      <th>Std_Train_Acc</th>\n",
       "      <th>Test_Acc</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.032969</td>\n",
       "      <td>0.737013</td>\n",
       "      <td>{'logreg__penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>{'svc__C': 0.7, 'svc__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.035721</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>{'rf__max_depth': 15, 'rf__max_features': 'aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.795652</td>\n",
       "      <td>0.046828</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>{'gb__max_depth': 5, 'gb__min_samples_leaf': 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "* All four models appear sensible choices, being sensible for binary classification problems. \n",
    "* There is approximately 3-5% variation in the 5-fold cross validation scores for each estimator.\n",
    "* The Gradient Boosting classifier appears to have marginally better train and test performance than the other classifers. SVC performs well too.\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "1d6f380379b7dc618cf8f0a55896905621e1b5753f35d08f03d770a4db2aecad"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}